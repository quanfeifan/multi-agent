#!/usr/bin/env python3
"""æ™ºèƒ½æœç´¢æ¼”ç¤º - ç»“åˆ LLM å’Œ MCP å·¥å…·å®ç°æ™ºèƒ½æœç´¢.

This example demonstrates:
1. Using LLM to decide when to use MCP search tools
2. LLM analyzing user queries and choosing appropriate search strategies
3. Automatically invoking MCP tools and formatting results for the user
"""

import argparse
import asyncio
import os
import sys
from pathlib import Path

# Load .env file
from dotenv import load_dotenv
load_dotenv()

# Add src to path for imports
sys.path.insert(0, str(Path(__file__).parent.parent.parent / "src"))

from openai import OpenAI

from multi_agent.config.loader import load_mcp_servers_config
from multi_agent.models.tool import MCPServer, MCPServerConfigSSE
from multi_agent.tools.mcp_manager import MCPToolManager
from multi_agent.tools.builtin import register_builtin_tools


def config_to_server(name: str, config):
    """Convert MCPServerConfig to MCPServer model."""
    if config.transport == "sse":
        server_config = MCPServerConfigSSE(
            url=config.config.url,
            headers=config.config.headers,
        )
    else:
        raise ValueError(f"Unsupported transport: {config.transport}")

    return MCPServer(
        name=name,
        transport=config.transport,
        config=server_config,
        description=config.description,
        enabled=config.enabled,
    )


class IntelligentSearchAgent:
    """æ™ºèƒ½æœç´¢ä»£ç† - ç»“åˆ LLM å’Œ MCP å·¥å…·."""

    def __init__(self, mcp_manager: MCPToolManager, api_key: str, base_url: str):
        """Initialize the intelligent search agent.

        Args:
            mcp_manager: MCPToolManager instance
            api_key: SiliconFlow API key
            base_url: API base URL
        """
        self.mcp_manager = mcp_manager
        self.client = OpenAI(api_key=api_key, base_url=base_url)

        # è·å–å¯ç”¨çš„æœç´¢å·¥å…·
        self.available_tools = self._get_available_tools()

    def _get_available_tools(self):
        """è·å–å¯ç”¨çš„æœç´¢å·¥å…·åˆ—è¡¨."""
        tools = self.mcp_manager.list_tools()
        search_tools = {}

        for tool in tools:
            if "search" in tool.name.lower() or "web" in tool.name.lower():
                search_tools[tool.name] = {
                    "name": tool.name,
                    "description": tool.description,
                    "input_schema": tool.input_schema,
                }

        return search_tools

    def _build_system_prompt(self):
        """æ„å»ºç³»ç»Ÿæç¤ºè¯."""
        tools_desc = "\n".join([
            f"- {name}: {desc['description']}"
            for name, desc in self.available_tools.items()
        ])

        return f"""ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½æœç´¢åŠ©æ‰‹ï¼Œå¯ä»¥å¸®åŠ©ç”¨æˆ·æœç´¢ç½‘ç»œä¿¡æ¯ã€‚

## å¯ç”¨å·¥å…·

{tools_desc}

## å·¥ä½œæµç¨‹

1. åˆ†æç”¨æˆ·çš„é—®é¢˜
2. åˆ¤æ–­æ˜¯å¦éœ€è¦ä½¿ç”¨æœç´¢å·¥å…·ï¼š
   - å¦‚æœé—®é¢˜æ¶‰åŠå®æ—¶ä¿¡æ¯ã€æ—¶äº‹æ–°é—»ã€æŠ€æœ¯é—®é¢˜ç­‰ï¼Œåº”è¯¥ä½¿ç”¨æœç´¢
   - å¦‚æœæ˜¯ç®€å•çš„é—²èŠæˆ–å¸¸è¯†æ€§é—®é¢˜ï¼Œå¯ä»¥ç›´æ¥å›ç­”
3. å¦‚æœéœ€è¦æœç´¢ï¼š
   - é€‰æ‹©æœ€åˆé€‚çš„æœç´¢å·¥å…·
   - ä½¿ç”¨æœç´¢æŸ¥è¯¢å‚æ•°ï¼šsearch_query
   - ä»æœç´¢ç»“æœä¸­æå–å…³é”®ä¿¡æ¯ï¼Œç”¨ç®€æ´å‹å¥½çš„æ–¹å¼å‘ˆç°ç»™ç”¨æˆ·

## è¾“å‡ºæ ¼å¼

### ä¸éœ€è¦æœç´¢æ—¶ï¼š
ç›´æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼Œæ ¼å¼ç®€æ´å‹å¥½ã€‚

### éœ€è¦æœç´¢æ—¶ï¼š
é¦–å…ˆè¾“å‡ºä¸€æ®µç®€çŸ­çš„è¯´æ˜ï¼Œç„¶åæŒ‰ä»¥ä¸‹JSONæ ¼å¼è°ƒç”¨å·¥å…·ï¼š

```json
{{
    "tool": "å·¥å…·åç§°",
    "search_query": "æœç´¢å…³é”®è¯"
}}
```

æœç´¢å®Œæˆåï¼Œä½ éœ€è¦æ•´ç†æœç´¢ç»“æœï¼Œç”¨ç®€æ´å‹å¥½çš„æ–¹å¼å‘ˆç°ç»™ç”¨æˆ·ã€‚

## æ³¨æ„äº‹é¡¹

- æœç´¢å…³é”®è¯åº”è¯¥ç®€æ´æ˜äº†ï¼Œç›´å‡»è¦ç‚¹
- ä»æœç´¢ç»“æœä¸­æå–æœ€ç›¸å…³çš„ä¿¡æ¯
- å›ç­”è¦ç”¨ä¸­æ–‡ï¼Œæ ¼å¼æ¸…æ™°ï¼Œä½¿ç”¨emojiå¢å¼ºå¯è¯»æ€§
- å¦‚æœæœç´¢ç»“æœä¸æ»¡æ„ï¼Œå¯ä»¥å°è¯•ä¸åŒçš„å…³é”®è¯å†æ¬¡æœç´¢
"""

    async def _call_search_tool(self, tool_name: str, search_query: str):
        """è°ƒç”¨ MCP æœç´¢å·¥å…·.

        Args:
            tool_name: å·¥å…·åç§°
            search_query: æœç´¢å…³é”®è¯

        Returns:
            æœç´¢ç»“æœ
        """
        # è·å–å¯¹åº”çš„ transport
        transport_name = None
        for name in self.mcp_manager.transports:
            if "search" in name.lower() or "web" in name.lower():
                transport_name = name
                break

        if not transport_name:
            return {"error": "æœªæ‰¾åˆ°æœç´¢å·¥å…·"}

        transport = self.mcp_manager.transports[transport_name]

        try:
            from multi_agent.tools.mcp_client import MCPMessage

            message = MCPMessage(
                method="tools/call",
                params={
                    "name": tool_name,
                    "arguments": {"search_query": search_query}
                }
            )

            response = await transport.send_message(message)

            if response.result:
                if isinstance(response.result, dict) and "content" in response.result:
                    for content_item in response.result["content"]:
                        if content_item.get("type") == "text":
                            return {"result": content_item.get("text", "")}

            return response.result if response.result else {"error": "æ— æœç´¢ç»“æœ"}

        except Exception as e:
            return {"error": f"æœç´¢å¤±è´¥: {str(e)}"}

    def _parse_tool_call(self, response: str):
        """è§£æ LLM è¿”å›çš„å·¥å…·è°ƒç”¨.

        Args:
            response: LLM å“åº”æ–‡æœ¬

        Returns:
            (tool_name, search_query) æˆ– None
        """
        import json
        import re

        # æŸ¥æ‰¾ JSON æ ¼å¼çš„å·¥å…·è°ƒç”¨
        json_match = re.search(r'\{[^{}]*"tool"[^{}]*"search_query"[^{}]*\}', response, re.DOTALL)
        if json_match:
            try:
                tool_call = json.loads(json_match.group())
                return tool_call.get("tool"), tool_call.get("search_query")
            except json.JSONDecodeError:
                pass

        return None, None

    async def search(self, user_query: str, max_iterations: int = 3):
        """æ™ºèƒ½æœç´¢ä¸»æµç¨‹.

        Args:
            user_query: ç”¨æˆ·æŸ¥è¯¢
            max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼ˆé˜²æ­¢æ— é™å¾ªç¯ï¼‰

        Returns:
            æœç´¢ç»“æœ
        """
        print(f"\nğŸ¤” ç”¨æˆ·é—®é¢˜: {user_query}\n")

        messages = [
            {"role": "system", "content": self._build_system_prompt()},
            {"role": "user", "content": user_query}
        ]

        for iteration in range(max_iterations):
            try:
                # è°ƒç”¨ LLM
                response = self.client.chat.completions.create(
                    model="Qwen/Qwen3-8B",
                    messages=messages,
                    temperature=0.7,
                    max_tokens=2000
                )

                assistant_message = response.choices[0].message.content
                messages.append({"role": "assistant", "content": assistant_message})

                # æ£€æŸ¥æ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·
                tool_name, search_query = self._parse_tool_call(assistant_message)

                if tool_name and search_query:
                    print(f"ğŸ” æ­£åœ¨æœç´¢: {search_query}")
                    print(f"   ä½¿ç”¨å·¥å…·: {tool_name}\n")

                    # è°ƒç”¨ MCP æœç´¢å·¥å…·
                    search_result = await self._call_search_tool(tool_name, search_query)

                    # æ ¼å¼åŒ–æœç´¢ç»“æœ
                    if "error" in search_result:
                        tool_response = f"æœç´¢é‡åˆ°é—®é¢˜: {search_result['error']}"
                    else:
                        raw_result = search_result.get("result", "")
                        # æˆªå–å‰2000å­—ç¬¦é¿å…tokenè¿‡å¤š
                        tool_response = f"æœç´¢ç»“æœå¦‚ä¸‹ï¼š\n\n{raw_result[:2000]}"

                    print(f"ğŸ“Š æœç´¢å®Œæˆ!\n")

                    # å°†å·¥å…·è°ƒç”¨ç»“æœæ·»åŠ åˆ°å¯¹è¯å†å²
                    messages.append({
                        "role": "user",
                        "content": f"å·¥å…· {tool_name} è¿”å›çš„ç»“æœï¼š\n{tool_response}\n\nè¯·æ•´ç†å¹¶æ€»ç»“æœç´¢ç»“æœï¼Œç”¨ç®€æ´å‹å¥½çš„æ–¹å¼å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚"
                    })

                    # å†æ¬¡è°ƒç”¨ LLM æ•´ç†ç»“æœ
                    final_response = self.client.chat.completions.create(
                        model="Qwen/Qwen3-8B",
                        messages=messages,
                        temperature=0.7,
                        max_tokens=2000
                    )

                    final_answer = final_response.choices[0].message.content
                    return final_answer
                else:
                    # ä¸éœ€è¦æœç´¢ï¼Œç›´æ¥è¿”å› LLM å›ç­”
                    return assistant_message

            except Exception as e:
                error_msg = f"å¤„ç†è¿‡ç¨‹å‡ºé”™: {str(e)}"
                print(f"âŒ {error_msg}\n")
                return error_msg

        return "æŠ±æ­‰ï¼Œæœç´¢è¿‡ç¨‹ä¸­é‡åˆ°äº†é—®é¢˜ã€‚"


async def main():
    """ä¸»å‡½æ•°."""
    parser = argparse.ArgumentParser(description="æ™ºèƒ½æœç´¢æ¼”ç¤º - ç»“åˆ LLM å’Œ MCP å·¥å…·")
    parser.add_argument(
        "query",
        nargs="?",
        help="æœç´¢é—®é¢˜ï¼ˆå¦‚æœä¸æä¾›ï¼Œå°†è¿›å…¥äº¤äº’æ¨¡å¼ï¼‰"
    )
    parser.add_argument(
        "--api-key",
        default=None,
        help="SiliconFlow API key (ä»ç¯å¢ƒå˜é‡ SILICONFLOW_API_KEY è¯»å–)"
    )
    parser.add_argument(
        "--base-url",
        default="https://api.siliconflow.cn/v1",
        help="API base URL"
    )
    parser.add_argument(
        "--config",
        default="examples/config/mcp_servers_modelscope.yaml",
        help="MCP æœåŠ¡å™¨é…ç½®æ–‡ä»¶è·¯å¾„"
    )
    parser.add_argument(
        "--interactive",
        "-i",
        action="store_true",
        help="äº¤äº’æ¨¡å¼ï¼ˆå¯ä»¥æŒç»­æé—®ï¼‰"
    )
    args = parser.parse_args()

    # ä»ç¯å¢ƒå˜é‡è¯»å– API keyï¼ˆä¼˜å…ˆçº§ï¼šå‘½ä»¤è¡Œå‚æ•° > ç¯å¢ƒå˜é‡ï¼‰
    api_key = args.api_key or os.getenv("SILICONFLOW_API_KEY")
    if not api_key:
        print("âŒ é”™è¯¯: è¯·è®¾ç½® SiliconFlow API key")
        print()
        print("ä½¿ç”¨æ–¹å¼:")
        print("  export SILICONFLOW_API_KEY='your_api_key_here'")
        print("  æˆ–")
        print("  python ai_search_demo.py --api-key 'your_api_key_here'")
        print()
        print("è·å– API Key: https://siliconflow.cn/")
        sys.exit(1)

    print("=" * 60)
    print("ğŸ¤– æ™ºèƒ½æœç´¢æ¼”ç¤º")
    print("=" * 60)
    print()

    # åˆå§‹åŒ– MCP ç®¡ç†å™¨
    print("ğŸ“¦ åˆå§‹åŒ– MCP å·¥å…·...")
    manager = MCPToolManager()
    servers_file = Path(args.config)

    # åŠ è½½ MCP æœåŠ¡å™¨é…ç½®
    if servers_file.exists():
        try:
            servers_config = load_mcp_servers_config(servers_file)
            for name, config in servers_config.items():
                if config.enabled and config.transport == "sse":
                    try:
                        server = config_to_server(name, config)
                        await manager.add_server(server)
                    except Exception as e:
                        print(f"  âš ï¸  Failed to load {name}: {e}")
        except Exception as e:
            print(f"  âš ï¸  Failed to load config: {e}")

    # æ£€æŸ¥å¯ç”¨å·¥å…·
    mcp_tools = manager.list_tools()
    print(f"âœ… å·²åŠ è½½ {len(mcp_tools)} ä¸ª MCP å·¥å…·\n")

    # åˆå§‹åŒ–æ™ºèƒ½æœç´¢ä»£ç†
    agent = IntelligentSearchAgent(
        mcp_manager=manager,
        api_key=api_key,
        base_url=args.base_url
    )

    async def process_query(query: str):
        """å¤„ç†å•ä¸ªæŸ¥è¯¢."""
        result = await agent.search(query)
        print("=" * 60)
        print("ğŸ’¡ æ™ºèƒ½å›ç­”")
        print("=" * 60)
        print()
        print(result)
        print()
        print("=" * 60)

    # å¤„ç†æŸ¥è¯¢
    if args.query:
        # å•æ¬¡æŸ¥è¯¢æ¨¡å¼
        await process_query(args.query)
    else:
        # äº¤äº’æ¨¡å¼
        print("ğŸ“ äº¤äº’æ¨¡å¼å·²å¯åŠ¨ï¼ˆè¾“å…¥ 'quit' æˆ– 'exit' é€€å‡ºï¼‰")
        print()

        while True:
            try:
                query = input("ğŸ¤” è¯·è¾“å…¥æ‚¨çš„é—®é¢˜: ").strip()
                if not query:
                    continue

                if query.lower() in ["quit", "exit", "é€€å‡º", "q"]:
                    print("ğŸ‘‹ å†è§ï¼")
                    break

                await process_query(query)

            except KeyboardInterrupt:
                print("\nğŸ‘‹ å†è§ï¼")
                break
            except EOFError:
                break

    # æ¸…ç†
    await manager.close()


if __name__ == "__main__":
    asyncio.run(main())
